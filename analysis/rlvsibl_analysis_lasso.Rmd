---
title: "RL vs IBL Project Analysis"
output:
  html_document:
    code_folding: hide
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(ggthemes)
library(ppcor)
library(reshape2)
#library(gglasso)
library(glmnet)
library(ggsci)
library(viridis)
library(ggExtra)
library(kableExtra)
library(xtable)
library(ggrepel)
library(scales)
library(car)
library(pROC)
library(patchwork)      # Multi-plot alignment
#library(data.table)

```

# Load and transform the data for every subject

First, let's load the Power 2011 region database. This will be used as an "atlas" throughout, to guide the development of the regions.

```{r}
power2011 <- read_csv("../bin/power_2011.csv", 
                      col_types = cols(ROI=col_double(),
                                       X = col_double(),
                                       Y = col_double(),
                                       Z = col_double(),
                                       Network = col_double(),
                                       Color = col_character(),
                                       NetworkName = col_character())) %>%
  dplyr::select(ROI, X, Y, Z, Network, Color, NetworkName)
```


Then, let's create the functional connectivity matrix for every single subject in the dataset. This step can be skipped by setting the `CREATE_FC` variable to `F`. 


## Load the group-level data

We now need to load the group level data. In essence, to corresponds to create a matrix _X_ in which every individual is a row and every columns is a different ROI-to-ROI connection.

```{r}
NOFLY <- c()
SUBJS <- c()
cols <- outer(power2011$ROI, power2011$ROI, function(x, y) {paste(x, y, sep="-")})
cols %<>% as.vector

connection <- function(x, y) {
  paste(min(x, y), max(x, y), sep="-")
}

vconnection <- Vectorize(connection)

Mode <- function(x, na.rm=F) {
  if (na.rm) {
    x = x[!is.na(x)]
  }
  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}

reduced_power2011 <- power2011 %>% 
  dplyr::select(Network, NetworkName) %>%
  group_by(Network) %>%
  summarize(Network = mean(Network), NetworkName = Mode(NetworkName))

connection_name <- function(x, y) {
  first <- min(x, y)
  second <- max(x, y)
  paste(reduced_power2011 %>% filter(Network == first) %>% dplyr::select(NetworkName) ,
        reduced_power2011 %>% filter(Network == second) %>% dplyr::select(NetworkName),
        sep="-")
  
}

vconnection_name <- Vectorize(connection_name)

connection_name2 <- function(x, y) {
  first <- min(x, y)
  second <- max(x, y)
  paste(reduced_power2011$NetworkName[reduced_power2011$Network == first],
        reduced_power2011$NetworkName[reduced_power2011$Network == second],
        sep="-")
  
}

vconnection_name2 <- Vectorize(connection_name2)


nets <- outer(power2011$Network, power2011$Network, vconnection)
nets %<>% as.vector
netnames <- outer(power2011$Network, power2011$Network, vconnection_name2)
netnames %<>% as.vector

n <- length(grep("sub-*", dir("../rsfmri/REST1")))
C <- matrix(data = rep(0, length(cols)*n), nrow =  n)

j <- 1

R <- NULL
PR <- NULL

for (sub in dir("../rsfmri/REST1")[grep("sub-*", dir("../rsfmri/REST1"))]) {
  SUBJS %<>% c(strsplit(sub, "-")[[1]][2])
  M <- paste("../rsfmri/REST1", 
             sub, 
             "ses-01/raw_pcorr.txt", sep="/") %>%
    read_csv(skip = 1,
             col_names = F,
             col_types = cols(
               .default = col_double(),
               X1 = col_character()
             )) %>%
    as.matrix() 
  v <- as_vector(M[,2:265])  # v spreads M column-wise. M is symmetrical, so it should not matter, but better not risk it
  #print(c(length(v), mean(v)))
  C[j,] <- v
  if (length(v[is.na(v)]) > 0) {
    print(paste("NA detected in sub", sub))
    NOFLY %<>% c(sub)  # Addes sub to NOFLY list
  }
  
  j <- j + 1
}

# Create python-compatible data
#
# for (sub in dir()[grep("sub-*", dir())]) {
#   R1 <- read.table(paste(sub, "R.txt", sep="/"))
#   R2 <- read.table(paste(sub, "PR.txt", sep="/"))
#   write.table(R1, paste(sub, "R_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
#   write.table(R2, paste(sub, "PR_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
# }

```

## Define the Networks

Now, we can restrict the analysis only to a limited set of networks (and their cross-network connections) by modifying the `NOI` (Networks of Interest) variable. The variable will be used to create a second list, `COI` (Connections of interest), which will contain the possible list of network-to-network connections 

```{r}
NOI <- c(
  "Uncertain",
  "Sensory/somatomotor Hand",
  "Sensory/somatomotor Mouth",
  "Cingulo-opercular Task Control",
  "Auditory",
  "Default mode",
  "Memory retrieval?",
  "Ventral attention",
  "Visual",
  "Fronto-parietal Task Control",
  "Salience",
  "Subcortical",
  "Cerebellar",
  "Dorsal attention"
)

COI <- outer(NOI, 
             NOI, 
             function(x, y) {paste(x, y, sep="-")}) %>% as.vector()
```


Now, we need to remove some columns from the hyper-large X matrix, and define proper groupings for Lasso.

```{r}
# Ensure the data is numeric

C <- apply(C, 2, FUN=as.numeric)
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI, 
                power2011$ROI, 
                function(x, y) {x < y}) %>% as.vector()

censor2 <- colMeans(C) %>% abs() > 0.05

order <- tibble(index = 1:length(nets), 
                network = nets, 
                network_names = netnames,
                connection = cols, 
                censor=censor,
                censor2 = censor2)
order %<>% arrange(network)


I <- order %>%
  filter(censor == TRUE) %>%
  filter(censor2 == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(index) 

G <- order %>%
  filter(censor == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(network) 
# G is the real grouping factor for Lasso!

# The real X:
X <- C[,as_vector(I)]
```

## Load the dependent variable $Y$

Now we need to load the dependent variable. In this case, it is the rate of forgetting $alpha$, which is stored as part of the participants' meta-data in `participats.tsv`. 

Note that we could not measure $alpha$ for all participants, so we have to keep track of which rows in the $X$ regressor matrix we want to exclude from our Lasso analysis.

```{r}
dvs <- read_csv("../actr-models/model_output/MODELLogLikelihood.csv") %>% 
  dplyr::select(HCPID, best_model) %>%
  arrange(HCPID)
```

Now we select only the rows of $X$ and the values of $Y$ for which we have both rsfMRI and model data:

```{r}
subjs_hcp <- paste(SUBJS, "fnca", sep="_")
common <- intersect(subjs_hcp, dvs$HCPID)
keep_X <- subjs_hcp %in% common
keep_Y <- dvs$HCPID %in% common
Y <- dvs$best_model[keep_Y]
X <- X[keep_X, ]
```

Finally, we transform the dependent variable $Y$ into a binary numeric variable, so that we can use logistic regression.

```{r}
Y <- as.numeric(as.factor(Y)) - 1
```

## Collinearity of Connectivity Regressors

The regressors $X$ is certainly multi-collinear. To gather a sense of how much it is so, we can plot the distribution of correlations among regressors:

```{r}
corX <- cor(X)
distCor <- as_vector(corX[lower.tri(corX, diag = F)])
distTibble <- as_tibble(data.frame(R=distCor))

ggplot(distTibble, aes(x=R)) +
  geom_histogram(col="white") +
  theme_pander() +
  ylab("Number of Correlations") +
  xlab("Correlation Value") +
  ggtitle("Distribution of Correlation Values Between Regressors")

```

And now, let's visualize the historgram of the dependent variable we are trying to predict:

```{r}
dependent <- as_tibble(data.frame(strategy=Y))
#d3 <- pal_d3()
#kol = d3(7)

ggplot(dependent, aes(x=strategy)) +
  geom_histogram(bins=8, col="white", alpha=0.5) +
  geom_vline(xintercept = mean(dependent$alpha)) +
  xlab("Strategy") +
  ylab("Number of Participants") +
  ggtitle("Distribution of Strategy Use") +
  theme_pander() +
  theme(legend.position = "none")

```

# Machine-Learning with Lasso

To analyzie the data, we will use Lasso, a statitical learning system based on penalyzed regression.

## Weights

Here we should maybe do oversampling? Most of the model fits are coded as "0", which creates an imbalance. We are going to create an appropriate set of weights so that the two classes are balanced.
```{r}
W <- Y
W[W == 0] <- mean(Y)
W[W == 1] <- (1-mean(Y))
```

## Defining the model

```{r}
fit <- glmnet(y = Y,
              x = X,
              alpha=1,
              weights = W,
              family = "binomial",
              type.measure = "class",

              #lambda.min = 0.5,
             #lam= 0.04978707,#log(length(Y)),
              standardize = T
)

#fit.cv <- cv.ncvreg(y = Y,

fit.cv <- cv.glmnet(y = Y,
                    x = X,
                    alpha=1,
                    family = "binomial",
                    weights = W,
                    type.measure = "class",
                    # lam=exp(seq(-3, -10, -0.1)),
                   #penalty="SCAD",
                    standardize=T,
                    nfolds=length(Y)
)

plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")

L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
```

And now, plot prettier version

```{r, fig.width=6, fig.height=4}
lasso_df <- as_tibble(data.frame(lambda=fit.cv$lambda, 
                                 error=fit.cv$cvm, 
                                 sd=fit.cv$cvsd))

ggplot(lasso_df, aes(x=lambda, y=error)) +
  geom_line(aes(col=error), lwd=2) +
  scale_color_viridis("Error", option = "plasma") +
  geom_ribbon(aes(ymin=error -sd, ymax=error + sd), alpha=0.2,fill="blue") +
  xlab(expression(lambda)) +
  ylab("Cross-Validation Error") +
  ggtitle(expression(paste(bold("Cross Validation Error Across "), lambda))) +
  geom_vline(xintercept = lasso_df$lambda[lasso_df$error==min(lasso_df$error)]) +
  theme_pander() +
  theme(legend.position="right")
```

## Examining the Predictive Connectome

Let's have a better look at the relevant connections.

```{r}
betas <- fit$beta[, which(fit$lambda==fit.cv$lambda.1se)]
conn_betas <- as_tibble(data.frame(index=I$index, Beta=betas))
connectome <- order %>%
   filter(index %in% I$index) %>%
   inner_join(conn_betas) %>%
  dplyr::select(-censor2) %>%
   filter(Beta != 0) %>%
  arrange(index)

write_csv(connectome, file="strategy.csv")
save(fit, fit.cv, X, Y, order, I, G, file="strategy.RData")

```

Finally, we can visualize the table of connections

```{r}
connectome %>%
  xtable() %>%
  kable(digits = 5) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

And we can do some statistics. For example, which networks do these regions and connections belong to? Are they different from what would be expected from a random sample of connections from the connectome?

```{r, fig.width=6, fig.height=8}
region_from <- function(s) {as.numeric(strsplit(s, "-")[[1]][1])}
region_to <- function(s) {as.numeric(strsplit(s, "-")[[1]][2])}

vregion_from <- Vectorize(region_from)
vregion_to <- Vectorize(region_to)

lROIs <- unique(c(vregion_from(connectome$connection),
                  vregion_to(connectome$connection)))

rois <- power2011[lROIs,]
roi_stats <- rois %>%
  group_by(NetworkName, Color) %>%
  summarise(N=length(Color)/length(lROIs)) %>%
  add_column(Source="Lasso")


subsetPower <- filter(power2011,
                      NetworkName %in% NOI)

noi_stats <- subsetPower %>%
  group_by(NetworkName, Color) %>%
  summarise(N=length(Color)/dim(subsetPower)[1]) %>%
  add_column(Source="Power")

total_stats <- rbind(roi_stats, noi_stats)

ggplot(total_stats, aes(x="", y=N, fill=NetworkName)) +
  geom_bar(stat = "identity", col="white", width=1) +
  facet_grid(~Source, labeller = label_both) +
  coord_polar("y", start=0) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2L)) +
  #scale_fill_viridis(discrete = T) +
  scale_fill_ucscgb() +
  ylab("") +
  xlab("") +
  ggtitle("Distriution of Regions") +
  geom_text_repel(aes(label=percent(N, .01)), col="black",
            position=position_stack(vjust=1), size=3)+
  theme_pander() +
  guides(fill=guide_legend(ncol=2)) +
  theme(legend.position = "bottom")
```

There is no difference in the distribution of ROIs:

```{r}
chisq.test(roi_stats$N*length(lROIs), p=noi_stats$N)
```

And now, let's look at the sparsity

```{r}

net_from <- function(s) {as.character(strsplit(s, "-")[[1]][1])}
net_to <- function(s) {as.character(strsplit(s, "-")[[1]][2])}

vnet_from <- Vectorize(net_from)
vnet_to <- Vectorize(net_to)

connectivity <- function(s) {
  if (net_from(s) == net_to(s)) {
    "Within"
  } else {
    "Between"
  }
}

vconnectivity <- Vectorize(connectivity)

coi <- order %>%
  filter(censor == TRUE) %>%
  filter(network_names %in% COI) 

coi$from <- vnet_from(coi$network_names)
coi$to <- vnet_to(coi$network_names)
coi$connection_type <- vconnectivity(coi$network_names)

coi_stats <- coi %>% 
  group_by(connection_type) %>% 
  summarise(N=length(index), P=length(index)/dim(coi)[1]) %>%
  add_column(Source = "Power et al. (2011)")
  

connectome$connection_type <- vconnectivity(connectome$network_names)
connectome_stats <- connectome %>%
  group_by(connection_type) %>% 
  summarise(N=length(index), P=length(index)/dim(connectome)[1]) %>%
  add_column(Source = "Lasso Analysis")
  

total_stats2 <- rbind(connectome_stats, coi_stats)

ggplot(total_stats2, aes(x="", y=P, fill=connection_type)) +
  geom_bar(stat = "identity", col="grey", width=1) +
  facet_grid(~Source, labeller = label_both) +
  coord_polar("y", start=0) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2L)) +
  scale_fill_jama() +
  scale_color_jama() +
  ylab("") +
  xlab("") +
  ggtitle("Distribuction of Connectivity\n(Within/Between Networks)") +
  geom_text_repel(aes(label=percent(P, .1)), col="white",
            position=position_stack(vjust=1), size=3)+
  theme_pander() +
  theme(legend.position = "bottom")
```

The differnece in distribution is  

```{r}
chisq.test(connectome_stats$N, p=coi_stats$P)
```


## Cross Validated Predictions

How well is the model doing? To investigate this, we can hand-craft a Leave-One Out regression model and save the predicted values of rate of forgetting as well as the recorded beta weights.

```{r}
dfX <- data.frame(cbind(Y, X[,betas != 0]))
numP <- ncol(X[, betas != 0])  
numO <- length(Y)
names(dfX) <- c("Y", paste("X", 1:numP, sep=""))

Yp <- rep(0, numO)  # Vector of zeros the size of Y 
Xe <- matrix(rep(0, numP * numO), 
             ncol = numP)  # Matrix of zeros the dimensions of X

for (i in seq(1, length(Y))) {
  subdfX <- dfX[-i,]
  lmod<-lm(Y ~ . + 1, as.data.frame(subdfX))
  
  yp <- predict(object=lmod, 
                newdata=dfX[i, 2:(numP + 1)])
  Yp[i] <- yp
  Xe[i,] <- lmod$coefficients[2:(numP + 1)]
}
```

Now, let's do a real predicted vs. observed graph:

```{r, fig.width=5, fig.height=5}
wcomparison <- tibble(Observed = Y,
                     Predicted = Yp)
              
p <- ggplot(wcomparison, aes(x=Predicted, y=Observed, 
                             col=(abs(100*(Predicted-Observed)/Observed)))) +
  geom_point(size=4, alpha=0.6) +
  geom_abline(intercept = 0, slope = 1, 
              col="red",
              linetype="dashed") +
  scale_color_viridis("% Absolute Error ", option="plasma", end=0.8) +
  theme_pander() +
#  geom_smooth(method="lm") +

  theme(legend.position = "right") +
#        legend.  = element_text()) +
#  guides(col=guide_legend("Error")) +
  coord_fixed(xlim=c(0, 1), ylim=c(0, 1)) +
  annotate("text", x=0.3, y=0.35,
           label=paste("r(33) =", 
                       floor(100*cor(Y, Yp))/100)) +
  ylab("Observed Strategy") +
  xlab("Predicted Strategy") +
  ggtitle("Decision Strategy:\nCross-Validation") +
  theme(legend.position = "bottom")
  
ggMarginal(p, 
           fill="blue", alpha=0.5,
           type="density", #bins=13, 
           col="blue",
           margins = "both")

```

And now, ROC to get the accuracy.

```{r}
wcomparison %<>% mutate(ROCPrediction = if_else(Predicted < 0.5, 0, 1))
rocobj <- roc(wcomparison$ROCPrediction, wcomparison$Observed)
g <- ggroc(rocobj, col="red") +
  geom_point(aes(y=rocobj$sensitivities, x=rocobj$specificities), col="red", size=4, alpha=.5) +
  ggtitle("ROC Curve for Model") +
  xlab("Specificity (FPR)") + ylab("Sensitivity (TPR)") + 
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="grey", linetype="dashed") +
  theme_pander()

g
```

The final accuracy of the prediction model is `r as.numeric(rocobj$auc)`

## Stability of Estimated Beta Weights

And now, let's visualize the beta weights of the connections

```{r, fig.width=8, fig.height=10}
colnames(Xe) <- paste("Connection", 1:nrow(connectome), paste="")
wconnections <- as_tibble(Xe)
lconnections <- pivot_longer(wconnections, cols=colnames(Xe), 
                             names_to="Connection", values_to = "Beta")

connectome <- connectome %>% arrange(Beta)

ggplot(lconnections, aes(x = reorder(Connection, Beta), y = Beta)) +
  geom_point(aes(col=Beta), alpha=.5, 
             size=2,
             position = position_jitter(height = 0, width = 0.3)) +
  stat_summary(fun.data = "mean_sdl", geom="point", fill="black", alpha=1, size=1) +
  scale_color_gradient2(low = "dodgerblue",
                        mid = "wheat",
                        high = "red2",
                        midpoint = 0) +
  scale_x_discrete(labels = 
                     paste(connectome$network_names, 
                           " (", 
                           connectome$connection,
                           ")", sep="")) +
  ggtitle("Connection Weights\nAcross Cross-Validation") +
  ylab(expression(paste(beta, " value"))) +
  xlab("Connection") +
  geom_hline(yintercept = 0, col="grey") +
  stat_summary(fun.data = "mean_cl_boot", 
               col="black", geom="errorbar", width=1) +
  #scale_color_viridis(option="plasma", begin=0.2, end=0.9) +
  
  theme_pander() +
  theme(axis.text.y = element_text(angle=0, hjust=1),
        legend.position = "NA") +
  #ylim(-3, 3) +
  coord_flip()
```


# Testing the validity of the Lasso model

To test the validity, we remove all the  connections with significant beta values, and check whether the results are still significant. 

## Ablation test

```{r}
XX <- X[, conn_betas$Beta == 0]

fit_wo <- glmnet(y = Y,
                 x = XX,
                 alpha=1,
                 lambda = fit$lambda,
                 family = "binomial",
                 type.measure = "class",
                 weights = W,
                 standardize = T
)

fit_wo.cv <- cv.glmnet(y = Y,
                       x = XX,
                       alpha=1,
                       weights = W,
                       lambda = fit$lambda,
                       standardize=T,
                       type.measure = "class",
                       family = "binomial",
                       
                       nfolds=length(Y)
)
```

The model does converge, but its overall classification error is much higher. 

```{r}
#plot(fit_wo.cv)
plot(fit_wo, sub="Beta Values for Connectivity")

L1norm <- sum(abs(fit_wo$beta[,which(fit_wo$lambda==fit_wo.cv$lambda.1se)]))
abline(v=L1norm, lwd=2, lty=2)
```

It is useful to plot the two $\lambda$-curves (with and without the relevant connections) on the same plot.

```{r fig.width=6, fig.height=4}
lasso_df_wo <- tibble(lambda=fit_wo.cv$lambda, 
                   error=fit_wo.cv$cvm, 
                   sd=fit_wo.cv$cvsd)



lasso_df$Model <- "Full Model"
lasso_df_wo$Model <- "Without the Selected Connections"

lasso_uber <- rbind(lasso_df, lasso_df_wo)

ggplot(lasso_uber, aes(x = lambda, y = error, fill=Model)) +
  scale_color_d3() +
  scale_fill_d3()+
  geom_ribbon(aes(ymin = error - sd, 
                  ymax = error + sd), 
              alpha = 0.5,
              #fill="blue"
              ) +
  geom_line(aes(col=Model), lwd=2) +
  xlab(expression(lambda)) +
  ylab("Cross-Validation Error") +
  ggtitle(expression(paste(bold("Cross Validation Error Across "), lambda))) +
  geom_vline(xintercept = fit.cv$lambda.1se,
             linetype="dashed") +
  theme_pander() +
  theme(legend.position="bottom")
```

## Variance Inflation Factor

Then, we examine the Variance Inflation Factor (VIF). To calculate the VIF, we need to first create a linear model of the factor effects:

```{r}
dfX <- data.frame(cbind(Y, X[,betas != 0]))
mod<-lm(Y ~ . + 1, as.data.frame(dfX))
```

We can now calculate the VIF and turn the results into a tibble: 

```{r}
vifs <- vif(mod)
vifsT <- tibble(VIF = vifs)
```

And, finally, we can plot an histogram of the distribution of VIF values. VIFs values < 10 are considered non-collinear; VIFs values < 5 are great.

```{r}
ggplot(vifsT, aes(x=VIF)) +
  geom_histogram(col="white", binwidth = 0.25, fill="blue", alpha=0.4) +
  theme_pander() +
  xlab("VIF Value") +
  ylab("Number of Predictors") +
  ggtitle("Distribution of Variance Inflation Factors")
```

## Connectivity by Region

Finally, we can look at how many connections exist for each region:

```{r}
rois <- c(vregion_from(connectome$connection), vregion_to(connectome$connection))
rois_t <- tibble(roi = rois)
rois_t %>%
  group_by(roi) %>%
  summarize(N = length(roi)) %>%
  arrange(N) %>%
  xtable() %>%
  kable(digits = 5) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```
